# -*- coding: utf-8 -*-
"""hw2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WZiI2--Zy4tTqWuwIL8k79WwzTrb8hWn
"""

from google.colab import drive
drive.mount('/content/drive')

import os
# os.chdir("/content/drive/MyDrive/....")  # file path
print(os.getcwd())

import numpy as np
import pandas as pd
import math
import random
from numpy import sqrt
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

input_data = pd.read_csv('hw2_input_basic.csv')
input_data

max_depth = 2
depth = 0
min_samples_split = 2
n_features = input_data.shape[1] - 1

def entropy(data):
  """
  This function measures the amount of uncertainty in a probability distribution
  args:
  * data(type: DataFrame): the data you're calculating for the entropy
  return:
  * entropy_value(type: float): the data's entropy
  """
  label_column = data.iloc[:,-1]
  cnt = np.bincount(label_column)
  prob = cnt/len(label_column)
  entropy_value = -1 * np.sum([p * np.log2(p) for p in prob if p > 0])


  return entropy_value

# [Note] You have to save the value of "ans_entropy" into the output file
ans_entropy = entropy(input_data)
print("ans_entropy = ", ans_entropy)

def cal_entropy(data):
  cnt = np.bincount(data)
  prob = cnt/len(data)
  entropy_value = -1 * np.sum([p * np.log2(p) for p in prob if p > 0])
  return entropy_value

def information_gain(data, mask):
  """
  This function will calculate the information gain
  args:
  * data(type: DataFrame): the data you're calculating for the information gain
  * mask(type: Series): partition information(left/right) of current input data,
    - boolean 1(True) represents split to left subtree
    - boolean 0(False) represents split to right subtree
  return:
  * ig(type: float): the information gain you can obtain by classify data with this given mask
  """
  #original_entropy = entropy(data)
  addition_mask = sum(mask)
  data_mask = mask.shape[0] - addition_mask

  if(addition_mask == 0 or data_mask == 0):
    ig = 0

  else:
      ig = entropy(data)-addition_mask/(addition_mask+data_mask)*entropy(data[mask])-data_mask/(addition_mask+data_mask)*entropy(data[-mask])

  return ig

# [Note] You have to save the value of "ans_informationGain" into your output file
temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)
temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)
temp_mask = np.concatenate((temp1, temp2))
df_mask = pd.DataFrame(temp_mask, columns=['mask'])
#print(df_mask)
ans_informationGain = information_gain(input_data, df_mask['mask'])
print("ans_informationGain = ", ans_informationGain)

def partition(data, column, threshold):

  match_branch = data.loc[data[column] <= threshold]
  false_branch = data.loc[data[column] > threshold]

  return match_branch, false_branch

def find_best_split(data):
  """
  This function will find the best split combination of data
  args:
  * data(type: DataFrame): the input data
  return
  * best_ig(type: float): the best information gain you obtain
  * best_threshold(type: float): the value that splits data into 2 branches
  * best_feature(type: string): the feature that splits data into 2 branches
  """
  all_entropy = 9999        #the overall entropy : save the value of the smallest entropy
  best_ig = 0
  best_feature = 0
  best_threshold = 0
  features_entropy = []
  # Recording current entropy
  data_entropy = entropy(data)
  n = len(data['diabetes_mellitus'])

  # Using foor loop through each columns in the dataframe
  for column in data:
    # Continue for column label
    if column == 'diabetes_mellitus':
      continue

    # Record unique values of each feature in data
    features_arr = data[[column]].to_numpy()
    features_arr = np.sort(features_arr, axis = None)
    unique_features_arr = np.unique(features_arr)

    # Get the unique middle values
    for idx in range(1, len(unique_features_arr)):
      features_entropy.append((unique_features_arr[idx-1] + unique_features_arr[idx]) / 2)

    # Partitioning the data and find the best entropy from it
    for e in features_entropy:
      match, false = partition(data, column, e)
      if len(match) == 0 or len(false) == 0:
            continue

      # Count information gain for both match and false dataframe
      match_ig = ((len(match['diabetes_mellitus']) / n) * entropy(match))
      false_ig = ((len(false['diabetes_mellitus']) / n) * entropy(false))

      current_entropy = data_entropy - (match_ig + false_ig)

      # Set entropy to best entropy if it is smaller than current entropy
      if current_entropy >= best_ig:
        best_ig = current_entropy
        best_feature = column
        best_threshold = e


  return best_ig, best_threshold, best_feature


# [Note] You have to save the value of "ans_ig", "ans_value", and "ans_name" into the output file
ans_ig, ans_value, ans_name = find_best_split(input_data)
print("ans_ig = ", ans_ig)
print("ans_value = ", ans_value)
print("ans_name = ", ans_name)

def make_partition(data, feature, threshold):
  """
  This function will split the data into 2 branches
  args:
  * data(type: DataFrame): the input data
  * feature(type: string): the attribute(column name)
  * threshold(type: float): the threshold for splitting the data
  return:
  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold
  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold
  """
  left = data.loc[data[feature] <= threshold]
  right = data.loc[data[feature] > threshold]

  return left, right


# [Note] You have to save the value of "ans_left" into the output file
left, right = make_partition(input_data, 'age', 61.0)
ans_left = left.shape[0]
print("ans_left = ", ans_left)

def build_tree(data, max_depth, min_samples_split, depth):
  """
  This function will build the decision tree
  args:
  * data(type: DataFrame): the data you want to apply to the decision tree
  * max_depth: the maximum depth of a decision tree
  * min_samples_split: the minimum number of instances required to do partition
  * depth: the height of the current decision tree
  return:
  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)
  """
  #X, y = data.iloc[:, :-1], data.iloc[:, -1]
  #n_samples, n_features = X.shape
  #feature=0
  #threshold=0
  # check the condition of current depth and the remaining number of samples
  if n_features > min_samples_split and depth < max_depth:
    # call find_best_split() to find the best combination
    curr_best_ig, threshold, feature = find_best_split(data)
    # check the value of information gain is greater than 0 or not
    if curr_best_ig > 0:
      # update the depth
      depth += 1
      # call make_partition() to split the data into two parts
      left,right = make_partition(data, feature, threshold)
      # If there is no data split to the left tree OR no data split to the left tree
      if len(left) == 0 or len(right) == 0:
        # return the label of the majority
        label = data.iloc[:,-1].mean()
        return label
      else:
        question = "{} {} {}".format(feature, "<=", threshold)
        subtree = {question: []}

        # call function build_tree() to recursively build the left subtree and right subtree
        left_subtree = build_tree(left, max_depth, min_samples_split, depth)
        right_subtree = build_tree(right, max_depth, min_samples_split, depth)
        if left_subtree == right_subtree:
          subtree = left_subtree
        else:
          subtree[question].append(left_subtree)
          subtree[question].append(right_subtree)
    else:
      # return the label of the majority
      label = data.iloc[:,-1].value_counts().idxmax()
      return label
  else:
    # return the label of the majority
    label = data.iloc[:,-1].value_counts().idxmax()
    return label

  return subtree

ans_features = []
ans_thresholds = []
decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)
decisionTree

# [Note] You have to save the features in the "decisionTree" structure (from root to branch and leaf) into the output file
tryl = "{}:{}".format(*(x for kv in decisionTree.items() for x in kv))
tryl
tryl = tryl.replace(' <= ',',')
tryl = tryl.replace(":[{'",',')
tryl = tryl.replace("':",',')
#tryl
ans = list(tryl.split(','))
ans
for index,data in enumerate(ans):
  if index == 0 or index == 2:
    ans_features.append(data)
  else:
    continue

ans_features

# [Note] You have to save the corresponding thresholds for the features in the "ans_features" list into the output file
for index,data in enumerate(ans):
  if index == 1 or index == 3:
    ans_thresholds.append(data)
  else:
    continue

ans_thresholds

basic = []
basic.append(ans_entropy)
basic.append(ans_informationGain)
basic.append(ans_ig)
basic.append(ans_value)
basic.append(ans_name)
basic.append(ans_left)
for i in range(len(ans_features)):
  basic.append(ans_features[i])
for m in range(len(ans_thresholds)):
  basic.append(ans_thresholds[m])

basic

num_train = 20
num_validation = 10

training_data = input_data.iloc[:num_train]
validation_data = input_data.iloc[-num_validation:]

y_train = training_data[["diabetes_mellitus"]]
x_train = training_data.drop(['diabetes_mellitus'], axis=1)
y_validation = validation_data[["diabetes_mellitus"]]
x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)
y_validation = y_validation.values.flatten()

print(input_data.shape)
print(training_data.shape)
print(validation_data.shape)
print(y_validation)

max_depth = 2
depth = 0
min_samples_split = 2
n_features = x_train.shape[1]

def classify_data(instance, tree):
  """
  This function will predict/classify the input instance
  args:
  * instance: a instance(case) to be predicted
  return:
  * answer: the prediction result (the classification result)
  """
  equation = list(tree.keys())[0]
  if equation.split()[1] == '<=':
    temp_feature = equation.split()[0]
    temp_threshold = equation.split()[2]
    if instance[temp_feature] > float(temp_threshold):
      answer = tree[equation][1]
    else:
      answer = tree[equation][0]
  else:
    if instance[equation.split()[0]] in (equation.split()[2]):
      answer = tree[equation][0]
    else:
      answer = tree[equation][1]

  if not isinstance(answer, dict):
    return answer
  else:
    return classify_data(instance, answer)


def make_prediction(tree, data):
  """
  This function will use your pre-trained decision tree to predict the labels of all instances in data
  args:
  * tree: the decision tree
  * data: the data to predict
  return:
  * y_prediction: the predictions
  """

  # [Note] You can call the function classify_data() to predict the label of each instance
  #y_prediction = data.apply(classify_data, axis = 1, args = (tree,))
  y_prediction = []
  index = data.index.tolist()
  for i in index:
      y_prediction.append(classify_data(data.loc[i],tree))

  return y_prediction


def calculate_score(y_true, y_pred):
  """
  This function will calculate the f1-score of the predictions
  args:
  * y_true: the ground truth
  * y_pred: the predictions
  return:
  * score: the f1-score
  """
  """TP, FP, TN, FN = 0, 0, 0, 0
  a = len(y_true) + 1
  for i in range(a):
      if   (y_true[i] == 0) & (y_pred[i] == 0):
          TP += 1
      elif (y_true[i] == 0) & (y_pred[i] == 1):
          FP += 1
      elif (y_true[i] == 1) & (y_pred[i] == 1):
          TN += 1
      else:
          FN += 1

  accuracy  = (TP + TN) / (TP + FP + TN + FN)
  precision = (TP) / (TP + FP)
  recall    = (TP) / (TP + FN)
  score  = (2 * precision * recall) / (precision + recall)
  """
  tp = 0
  for gt, pred in zip(y_true, y_pred):
      if gt == 1 and pred == 1:
          tp +=1

  tn = 0
  for gt, pred in zip(y_true, y_pred):
      if gt == 0 and pred == 0:
          tn +=1

  fp = 0
  for gt, pred in zip(y_true, y_pred):
      if gt == 0 and pred == 1:
          fp +=1

  fn = 0
  for gt, pred in zip(y_true, y_pred):
      if gt == 1 and pred == 0:
          fn +=1

  precision = tp/ (tp + fp)
  recall = tp/ (tp + fn)

  score = 2 * precision * recall/ (precision + recall)
  #score = f1_score(y_true, y_pred)

  return score

decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)

y_pred = make_prediction(decision_tree, x_validation)
print(y_pred)
# [Note] You have to save the value of "ans_f1score" the your output file
ans_f1score = calculate_score(y_validation, y_pred)
print("ans_f1score = ", ans_f1score)

ans_path = 'hw2_basic.csv'

# [Note] You have to save the value of "ans_f1score" into the output file
basic.append(ans_f1score)
print(basic)

pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)