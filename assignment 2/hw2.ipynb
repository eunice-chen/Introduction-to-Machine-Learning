{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive (optional)"
      ],
      "metadata": {
        "id": "fI00-KuddN2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "# os.chdir(\"/content/drive/MyDrive/....\")  # file path\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "Uf6ucZcj6kpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd8697b-bfee-4a37-9902-9fc731004fdc"
      },
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW2 : Decision Tree and Random Forest**\n",
        "In *assignment 2*, you need to finish :\n",
        "\n",
        "1. Basic Part : Implement a **Decision Tree** model and predict whether the patients in the validation set have diabetes\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Calculate the Entropy and Information Gain\n",
        "> * Step 3 : Find the Best Split\n",
        "> * Step 4 : Split into 2 branches\n",
        "> * Step 5 : Build decision tree\n",
        "> * Step 6 : Save the answers from step2 to step5\n",
        "> * Step 7 : Split data into training set and validation set\n",
        "> * Step 8 : Train a decision tree model with training set\n",
        "> * Step 9 : Predict the cases in the *validation set* by using the model trained in *Step8*\n",
        "> * Step 10 : Calculate the f1-score of your predictions in *Step9*\n",
        "> * Step 11 : Write the Output File\n",
        "\n",
        "2. Advanced Part : Build a **Random Forest** model to make predictions\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Load the test data\n",
        "> * Step 3 : Build a random forest\n",
        "> * Step 4 : Predict the cases in the test data by using the model trained in *Step3*\n",
        "> * Step 5 : Save the predictions(from *Step 4*) in a csv file\n",
        "\n"
      ],
      "metadata": {
        "id": "yvRo67Io4NKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Part** (60%)\n",
        "In this part, your need to implement a Decision Tree model by completing the following given functions.\n",
        "\n",
        "Also, you need to run these functions with the given input variables and save the output in a csv file **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "wwVh8lYD4kbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages\n",
        "\n",
        "\n",
        "> Note : You **cannot** import any other packages in both basic part and advanced part\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h2ibEyDa46X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from numpy import sqrt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "RMjaYVZD6kmb"
      },
      "execution_count": 599,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_basic.csv**"
      ],
      "metadata": {
        "id": "zrQXqH475G8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pd.read_csv('hw2_input_basic.csv')\n",
        "input_data"
      ],
      "metadata": {
        "id": "0n3gcL2l6kjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "9e4fa29b-3ac8-4911-f8d9-b5e3fed0a8e5"
      },
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age        bmi  gender  height  weight  glucose_apache  \\\n",
              "0   70.0  25.984659       1   172.7   77.50           116.0   \n",
              "1   30.0  31.310368       1   170.2   90.70            71.0   \n",
              "2   54.0  24.388824       1   177.8   77.10           120.0   \n",
              "3   65.0  34.141074       0   170.2   98.90            73.0   \n",
              "4   49.0  22.564743       1   172.7   67.30           207.0   \n",
              "5   62.0  29.424010       0   154.9   70.60           113.0   \n",
              "6   85.0  27.673574       1   154.9   66.40           102.0   \n",
              "7   65.0  22.269432       1   177.8   70.40           333.0   \n",
              "8   85.0  35.879362       0   165.1   97.80           124.0   \n",
              "9   81.0  20.859375       0   160.0   53.40           136.0   \n",
              "10  59.0  46.409136       0   162.6  122.70           169.0   \n",
              "11  77.0  32.324734       0   154.9   77.56           264.0   \n",
              "12  68.0  15.913579       1   185.4   54.70            39.0   \n",
              "13  51.0  24.028492       1   190.5   87.20            80.0   \n",
              "14  76.0  34.216873       0   154.9   82.10           306.0   \n",
              "15  48.0  26.516476       1   180.3   86.20            96.0   \n",
              "16  82.0  18.921389       0   154.9   45.40           164.0   \n",
              "17  78.0  36.668167       0   167.6  103.00           282.0   \n",
              "18  62.0  19.108088       1   157.5   47.40           275.0   \n",
              "19  73.0  22.851562       0   160.0   58.50           178.0   \n",
              "20  73.0  20.351971       0   167.5   57.10           159.0   \n",
              "21  59.0  27.109238       1   177.8   85.70            85.0   \n",
              "22  51.0  37.954367       0   172.7  113.20           168.0   \n",
              "23  80.0  36.267895       1   180.3  117.90           138.0   \n",
              "24  74.0  25.856081       1   170.2   74.90           145.0   \n",
              "25  61.0  29.161972       1   180.3   94.80           267.0   \n",
              "26  74.0  38.111136       1   188.0  134.70           279.0   \n",
              "27  65.0  53.414791       0   166.4  147.90           121.0   \n",
              "28  38.0  33.438787       0   161.3   87.00           135.0   \n",
              "29  82.0  32.263238       0   162.6   85.30           111.0   \n",
              "\n",
              "    heart_rate_apache  resprate_apache  sodium_apache  diabetes_mellitus  \n",
              "0               101.0             49.0          137.0                  0  \n",
              "1                39.0             33.0          144.0                  0  \n",
              "2               120.0             31.0          141.0                  0  \n",
              "3                48.0             36.0          140.0                  1  \n",
              "4               119.0              6.0          144.0                  0  \n",
              "5                60.0             32.0          137.0                  0  \n",
              "6                49.0             36.0          142.0                  0  \n",
              "7                59.0              6.0          145.0                  1  \n",
              "8                92.0             30.0          136.0                  0  \n",
              "9               118.0             52.0          138.0                  0  \n",
              "10              100.0             46.0          138.0                  0  \n",
              "11               90.0             37.0          141.0                  1  \n",
              "12              108.0             45.0          135.0                  0  \n",
              "13               61.0             30.0          139.0                  0  \n",
              "14              112.0             40.0          130.0                  1  \n",
              "15              133.0             31.0          137.0                  0  \n",
              "16              103.0             48.0          134.0                  0  \n",
              "17              104.0             42.0          138.0                  1  \n",
              "18              108.0             38.0          131.0                  1  \n",
              "19              154.0             55.0          138.0                  1  \n",
              "20              110.0             27.0          139.0                  0  \n",
              "21               92.0              6.0          143.0                  0  \n",
              "22               60.0             43.0          119.0                  1  \n",
              "23              178.0             43.0          140.0                  1  \n",
              "24               40.0             16.0          146.0                  1  \n",
              "25               62.0             58.0          134.0                  1  \n",
              "26              112.0             43.0          132.0                  1  \n",
              "27               88.0             32.0          142.0                  0  \n",
              "28               46.0             28.0          138.0                  0  \n",
              "29              114.0             22.0          143.0                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4948f206-f81d-40dd-8912-0842dded8777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>glucose_apache</th>\n",
              "      <th>heart_rate_apache</th>\n",
              "      <th>resprate_apache</th>\n",
              "      <th>sodium_apache</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70.0</td>\n",
              "      <td>25.984659</td>\n",
              "      <td>1</td>\n",
              "      <td>172.7</td>\n",
              "      <td>77.50</td>\n",
              "      <td>116.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.0</td>\n",
              "      <td>31.310368</td>\n",
              "      <td>1</td>\n",
              "      <td>170.2</td>\n",
              "      <td>90.70</td>\n",
              "      <td>71.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54.0</td>\n",
              "      <td>24.388824</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>77.10</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65.0</td>\n",
              "      <td>34.141074</td>\n",
              "      <td>0</td>\n",
              "      <td>170.2</td>\n",
              "      <td>98.90</td>\n",
              "      <td>73.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.0</td>\n",
              "      <td>22.564743</td>\n",
              "      <td>1</td>\n",
              "      <td>172.7</td>\n",
              "      <td>67.30</td>\n",
              "      <td>207.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>62.0</td>\n",
              "      <td>29.424010</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>70.60</td>\n",
              "      <td>113.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>85.0</td>\n",
              "      <td>27.673574</td>\n",
              "      <td>1</td>\n",
              "      <td>154.9</td>\n",
              "      <td>66.40</td>\n",
              "      <td>102.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>65.0</td>\n",
              "      <td>22.269432</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>70.40</td>\n",
              "      <td>333.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85.0</td>\n",
              "      <td>35.879362</td>\n",
              "      <td>0</td>\n",
              "      <td>165.1</td>\n",
              "      <td>97.80</td>\n",
              "      <td>124.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>81.0</td>\n",
              "      <td>20.859375</td>\n",
              "      <td>0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>53.40</td>\n",
              "      <td>136.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>59.0</td>\n",
              "      <td>46.409136</td>\n",
              "      <td>0</td>\n",
              "      <td>162.6</td>\n",
              "      <td>122.70</td>\n",
              "      <td>169.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>77.0</td>\n",
              "      <td>32.324734</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>77.56</td>\n",
              "      <td>264.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>68.0</td>\n",
              "      <td>15.913579</td>\n",
              "      <td>1</td>\n",
              "      <td>185.4</td>\n",
              "      <td>54.70</td>\n",
              "      <td>39.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>51.0</td>\n",
              "      <td>24.028492</td>\n",
              "      <td>1</td>\n",
              "      <td>190.5</td>\n",
              "      <td>87.20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>76.0</td>\n",
              "      <td>34.216873</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>82.10</td>\n",
              "      <td>306.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>48.0</td>\n",
              "      <td>26.516476</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>86.20</td>\n",
              "      <td>96.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>82.0</td>\n",
              "      <td>18.921389</td>\n",
              "      <td>0</td>\n",
              "      <td>154.9</td>\n",
              "      <td>45.40</td>\n",
              "      <td>164.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>78.0</td>\n",
              "      <td>36.668167</td>\n",
              "      <td>0</td>\n",
              "      <td>167.6</td>\n",
              "      <td>103.00</td>\n",
              "      <td>282.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>62.0</td>\n",
              "      <td>19.108088</td>\n",
              "      <td>1</td>\n",
              "      <td>157.5</td>\n",
              "      <td>47.40</td>\n",
              "      <td>275.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>73.0</td>\n",
              "      <td>22.851562</td>\n",
              "      <td>0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>58.50</td>\n",
              "      <td>178.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>73.0</td>\n",
              "      <td>20.351971</td>\n",
              "      <td>0</td>\n",
              "      <td>167.5</td>\n",
              "      <td>57.10</td>\n",
              "      <td>159.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>59.0</td>\n",
              "      <td>27.109238</td>\n",
              "      <td>1</td>\n",
              "      <td>177.8</td>\n",
              "      <td>85.70</td>\n",
              "      <td>85.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>51.0</td>\n",
              "      <td>37.954367</td>\n",
              "      <td>0</td>\n",
              "      <td>172.7</td>\n",
              "      <td>113.20</td>\n",
              "      <td>168.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>80.0</td>\n",
              "      <td>36.267895</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>117.90</td>\n",
              "      <td>138.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>74.0</td>\n",
              "      <td>25.856081</td>\n",
              "      <td>1</td>\n",
              "      <td>170.2</td>\n",
              "      <td>74.90</td>\n",
              "      <td>145.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>61.0</td>\n",
              "      <td>29.161972</td>\n",
              "      <td>1</td>\n",
              "      <td>180.3</td>\n",
              "      <td>94.80</td>\n",
              "      <td>267.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>74.0</td>\n",
              "      <td>38.111136</td>\n",
              "      <td>1</td>\n",
              "      <td>188.0</td>\n",
              "      <td>134.70</td>\n",
              "      <td>279.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>65.0</td>\n",
              "      <td>53.414791</td>\n",
              "      <td>0</td>\n",
              "      <td>166.4</td>\n",
              "      <td>147.90</td>\n",
              "      <td>121.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>38.0</td>\n",
              "      <td>33.438787</td>\n",
              "      <td>0</td>\n",
              "      <td>161.3</td>\n",
              "      <td>87.00</td>\n",
              "      <td>135.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>82.0</td>\n",
              "      <td>32.263238</td>\n",
              "      <td>0</td>\n",
              "      <td>162.6</td>\n",
              "      <td>85.30</td>\n",
              "      <td>111.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4948f206-f81d-40dd-8912-0842dded8777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4948f206-f81d-40dd-8912-0842dded8777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4948f206-f81d-40dd-8912-0842dded8777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global attributes\n",
        "Define the global attributes\n",
        "> Note : You **cannot** modify the values of these attributes we given in the basic part"
      ],
      "metadata": {
        "id": "BhtqUTG9Nlyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = input_data.shape[1] - 1"
      ],
      "metadata": {
        "id": "etfPC94oN_TO"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can add your own global attributes here"
      ],
      "metadata": {
        "id": "V1FN1Z-tOFOo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQ-OYop8ONnv"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Calculate the Entropy and Information Gain \n",
        "Calculate the information gain and entropy values before separate data into left subtree and right subtree"
      ],
      "metadata": {
        "id": "Gey7t_Yx5YML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(data):\n",
        "  \"\"\"\n",
        "  This function measures the amount of uncertainty in a probability distribution\n",
        "  args: \n",
        "  * data(type: DataFrame): the data you're calculating for the entropy\n",
        "  return:\n",
        "  * entropy_value(type: float): the data's entropy\n",
        "  \"\"\"\n",
        "  label_column = data.iloc[:,-1]\n",
        "  cnt = np.bincount(label_column)\n",
        "  prob = cnt/len(label_column)\n",
        "  entropy_value = -1 * np.sum([p * np.log2(p) for p in prob if p > 0])\n",
        "\n",
        "\n",
        "  return entropy_value\n",
        "\n",
        "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
        "ans_entropy = entropy(input_data)\n",
        "print(\"ans_entropy = \", ans_entropy)"
      ],
      "metadata": {
        "id": "hpdNz3ij6keH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a02f34-0103-4e62-d91d-5cd2fd5aa654"
      },
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_entropy =  0.9871377743721863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_entropy(data):\n",
        "  cnt = np.bincount(data)\n",
        "  prob = cnt/len(data)\n",
        "  entropy_value = -1 * np.sum([p * np.log2(p) for p in prob if p > 0])\n",
        "  return entropy_value"
      ],
      "metadata": {
        "id": "FsDJ0Kj4YMpI"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(data, mask):\n",
        "  \"\"\"\n",
        "  This function will calculate the information gain\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you're calculating for the information gain\n",
        "  * mask(type: Series): partition information(left/right) of current input data, \n",
        "    - boolean 1(True) represents split to left subtree\n",
        "    - boolean 0(False) represents split to right subtree\n",
        "  return:\n",
        "  * ig(type: float): the information gain you can obtain by classify data with this given mask\n",
        "  \"\"\"\n",
        "  #original_entropy = entropy(data)\n",
        "  addition_mask = sum(mask)\n",
        "  data_mask = mask.shape[0] - addition_mask\n",
        "  \n",
        "  if(addition_mask == 0 or data_mask == 0): \n",
        "    ig = 0\n",
        "  \n",
        "  else:\n",
        "      ig = entropy(data)-addition_mask/(addition_mask+data_mask)*entropy(data[mask])-data_mask/(addition_mask+data_mask)*entropy(data[-mask])\n",
        "\n",
        "  return ig\n",
        "\n",
        "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
        "temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)\n",
        "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)\n",
        "temp_mask = np.concatenate((temp1, temp2))\n",
        "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
        "#print(df_mask)\n",
        "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
        "print(\"ans_informationGain = \", ans_informationGain)"
      ],
      "metadata": {
        "id": "zCC_SiU26kbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ee3ce5-edff-40e4-8597-81eb338715b0"
      },
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_informationGain =  0.08345988684807151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Find the Best Split\n",
        "Find the best split combination, **feature** and **threshold**, by calculating the information gain\n"
      ],
      "metadata": {
        "id": "9r8mrn7A55if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(data, column, threshold):\n",
        "  \n",
        "  match_branch = data.loc[data[column] <= threshold]\n",
        "  false_branch = data.loc[data[column] > threshold]\n",
        "\n",
        "  return match_branch, false_branch"
      ],
      "metadata": {
        "id": "Faz1eqewzb0i"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(data):\n",
        "  \"\"\"\n",
        "  This function will find the best split combination of data\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  return\n",
        "  * best_ig(type: float): the best information gain you obtain\n",
        "  * best_threshold(type: float): the value that splits data into 2 branches\n",
        "  * best_feature(type: string): the feature that splits data into 2 branches\n",
        "  \"\"\"\n",
        "  all_entropy = 9999        #the overall entropy : save the value of the smallest entropy\n",
        "  best_ig = 0\n",
        "  best_feature = 0\n",
        "  best_threshold = 0\n",
        "  features_entropy = []\n",
        "  # Recording current entropy\n",
        "  data_entropy = entropy(data)\n",
        "  n = len(data['diabetes_mellitus'])\n",
        "\n",
        "  # Using foor loop through each columns in the dataframe\n",
        "  for column in data:\n",
        "    # Continue for column label\n",
        "    if column == 'diabetes_mellitus':\n",
        "      continue\n",
        "\n",
        "    # Record unique values of each feature in data\n",
        "    features_arr = data[[column]].to_numpy()\n",
        "    features_arr = np.sort(features_arr, axis = None)\n",
        "    unique_features_arr = np.unique(features_arr)      \n",
        "\n",
        "    # Get the unique middle values\n",
        "    for idx in range(1, len(unique_features_arr)):\n",
        "      features_entropy.append((unique_features_arr[idx-1] + unique_features_arr[idx]) / 2)\n",
        "\n",
        "    # Partitioning the data and find the best entropy from it    \n",
        "    for e in features_entropy:\n",
        "      match, false = partition(data, column, e)\n",
        "      if len(match) == 0 or len(false) == 0:\n",
        "            continue    \n",
        "\n",
        "      # Count information gain for both match and false dataframe\n",
        "      match_ig = ((len(match['diabetes_mellitus']) / n) * entropy(match)) \n",
        "      false_ig = ((len(false['diabetes_mellitus']) / n) * entropy(false))    \n",
        "\n",
        "      current_entropy = data_entropy - (match_ig + false_ig) \n",
        "      \n",
        "      # Set entropy to best entropy if it is smaller than current entropy\n",
        "      if current_entropy >= best_ig:\n",
        "        best_ig = current_entropy\n",
        "        best_feature = column\n",
        "        best_threshold = e\n",
        "\n",
        "  \n",
        "  return best_ig, best_threshold, best_feature\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
        "ans_ig, ans_value, ans_name = find_best_split(input_data)\n",
        "print(\"ans_ig = \", ans_ig)\n",
        "print(\"ans_value = \", ans_value)\n",
        "print(\"ans_name = \", ans_name)"
      ],
      "metadata": {
        "id": "D6gg7ig18XgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a57514-4cee-42c2-d406-c73d6cd987f1"
      },
      "execution_count": 606,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_ig =  0.3522950515812332\n",
            "ans_value =  235.5\n",
            "ans_name =  glucose_apache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Split into 2 branches\n",
        "Using the best split combination you find in function *find_best_split()* to split data into Left Subtree and Right Subtree "
      ],
      "metadata": {
        "id": "61hPUYvy6MTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_partition(data, feature, threshold):\n",
        "  \"\"\"\n",
        "  This function will split the data into 2 branches\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  * feature(type: string): the attribute(column name)\n",
        "  * threshold(type: float): the threshold for splitting the data\n",
        "  return:\n",
        "  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
        "  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
        "  \"\"\"\n",
        "  left = data.loc[data[feature] <= threshold]\n",
        "  right = data.loc[data[feature] > threshold]\n",
        "  \n",
        "  return left, right\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_left\" into the output file\n",
        "left, right = make_partition(input_data, 'age', 61.0)\n",
        "ans_left = left.shape[0]\n",
        "print(\"ans_left = \", ans_left)"
      ],
      "metadata": {
        "id": "KQRcjzCLCo4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7353e260-cbbc-4981-ecb3-e85dbc049d79"
      },
      "execution_count": 607,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_left =  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Build Decision Tree\n",
        "Use the above functions to implement the decision tree\n",
        "\n",
        "Instructions: \n",
        "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
        "2.  Use function *find_best_split()* to find the best split combination\n",
        "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
        "4. Use function *make_partition()* to split the data into two parts\n",
        "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLzy6Yhg802x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(data, max_depth, min_samples_split, depth):\n",
        "  \"\"\"\n",
        "  This function will build the decision tree\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you want to apply to the decision tree\n",
        "  * max_depth: the maximum depth of a decision tree\n",
        "  * min_samples_split: the minimum number of instances required to do partition\n",
        "  * depth: the height of the current decision tree\n",
        "  return:\n",
        "  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
        "  \"\"\"\n",
        "  #X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
        "  #n_samples, n_features = X.shape\n",
        "  #feature=0\n",
        "  #threshold=0\n",
        "  # check the condition of current depth and the remaining number of samples\n",
        "  if n_features > min_samples_split and depth < max_depth:\n",
        "    # call find_best_split() to find the best combination\n",
        "    curr_best_ig, threshold, feature = find_best_split(data)\n",
        "    # check the value of information gain is greater than 0 or not \n",
        "    if curr_best_ig > 0:\n",
        "      # update the depth\n",
        "      depth += 1\n",
        "      # call make_partition() to split the data into two parts\n",
        "      left,right = make_partition(data, feature, threshold)\n",
        "      # If there is no data split to the left tree OR no data split to the left tree\n",
        "      if len(left) == 0 or len(right) == 0:\n",
        "        # return the label of the majority\n",
        "        label = data.iloc[:,-1].mean()\n",
        "        return label\n",
        "      else:\n",
        "        question = \"{} {} {}\".format(feature, \"<=\", threshold)\n",
        "        subtree = {question: []}\n",
        "\n",
        "        # call function build_tree() to recursively build the left subtree and right subtree\n",
        "        left_subtree = build_tree(left, max_depth, min_samples_split, depth)\n",
        "        right_subtree = build_tree(right, max_depth, min_samples_split, depth)\n",
        "        if left_subtree == right_subtree:\n",
        "          subtree = left_subtree\n",
        "        else:\n",
        "          subtree[question].append(left_subtree)\n",
        "          subtree[question].append(right_subtree)\n",
        "    else:\n",
        "      # return the label of the majority\n",
        "      label = data.iloc[:,-1].value_counts().idxmax()\n",
        "      return label\n",
        "  else:\n",
        "    # return the label of the majority\n",
        "    label = data.iloc[:,-1].value_counts().idxmax()\n",
        "    return label\n",
        "\n",
        "  return subtree"
      ],
      "metadata": {
        "id": "_OAXVddKkvM2"
      },
      "execution_count": 608,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output from *build_tree()* \n",
        "```\n",
        "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
        "```\n",
        "Therefore, \n",
        "```\n",
        "ans_features = ['bmi', 'age']\n",
        "ans_thresholds = [33.5, 68.5]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qlIrw9Gu-M9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_features = []\n",
        "ans_thresholds = []\n",
        "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
        "decisionTree\n"
      ],
      "metadata": {
        "id": "QW8wm1rD9dlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e048ff-b915-42f0-e524-2822401321ff"
      },
      "execution_count": 609,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glucose_apache <= 235.5': [{'heart_rate_apache <= 143.5': [0, 1]}, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 609
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n",
        "tryl = \"{}:{}\".format(*(x for kv in decisionTree.items() for x in kv))\n",
        "tryl\n",
        "tryl = tryl.replace(' <= ',',')\n",
        "tryl = tryl.replace(\":[{'\",',')\n",
        "tryl = tryl.replace(\"':\",',')\n",
        "#tryl\n",
        "ans = list(tryl.split(','))\n",
        "ans\n",
        "for index,data in enumerate(ans):\n",
        "  if index == 0 or index == 2:\n",
        "    ans_features.append(data)\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "ans_features"
      ],
      "metadata": {
        "id": "v_n0BfNSGejN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7372b764-94ab-4a50-9547-c0c9e4b42b32"
      },
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glucose_apache', 'heart_rate_apache']"
            ]
          },
          "metadata": {},
          "execution_count": 610
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
        "for index,data in enumerate(ans):\n",
        "  if index == 1 or index == 3:\n",
        "    ans_thresholds.append(data)\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "ans_thresholds"
      ],
      "metadata": {
        "id": "D6H9zkN_GgK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fa0f67-332f-4e93-b746-699d02b1c240"
      },
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['235.5', '143.5']"
            ]
          },
          "metadata": {},
          "execution_count": 611
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step6 : Save answers"
      ],
      "metadata": {
        "id": "rP0SU7tTweOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic = []\n",
        "basic.append(ans_entropy)\n",
        "basic.append(ans_informationGain)\n",
        "basic.append(ans_ig)\n",
        "basic.append(ans_value)\n",
        "basic.append(ans_name)\n",
        "basic.append(ans_left)\n",
        "for i in range(len(ans_features)):\n",
        "  basic.append(ans_features[i])\n",
        "for m in range(len(ans_thresholds)):\n",
        "  basic.append(ans_thresholds[m])\n",
        "\n",
        "basic"
      ],
      "metadata": {
        "id": "sDO36kKEwh6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27bd5509-48f6-464a-e7cd-475e416d4d0e"
      },
      "execution_count": 612,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9871377743721863,\n",
              " 0.08345988684807151,\n",
              " 0.3522950515812332,\n",
              " 235.5,\n",
              " 'glucose_apache',\n",
              " 10,\n",
              " 'glucose_apache',\n",
              " 'heart_rate_apache',\n",
              " '235.5',\n",
              " '143.5']"
            ]
          },
          "metadata": {},
          "execution_count": 612
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step7 : Split data\n",
        "Split data into training set and validation set\n",
        "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
      ],
      "metadata": {
        "id": "7DotyrSZjYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 20\n",
        "num_validation = 10\n",
        "\n",
        "training_data = input_data.iloc[:num_train]\n",
        "validation_data = input_data.iloc[-num_validation:]\n",
        "\n",
        "y_train = training_data[[\"diabetes_mellitus\"]]\n",
        "x_train = training_data.drop(['diabetes_mellitus'], axis=1)\n",
        "y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
        "x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
        "y_validation = y_validation.values.flatten()\n",
        "\n",
        "print(input_data.shape)\n",
        "print(training_data.shape)\n",
        "print(validation_data.shape)\n",
        "print(y_validation)"
      ],
      "metadata": {
        "id": "WjNM-n4i5mlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816ea1e3-d733-4abd-81a3-a708fab411f2"
      },
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 10)\n",
            "(20, 10)\n",
            "(10, 10)\n",
            "[0 0 1 1 1 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step8 to Step10 : Make predictions with a decision tree"
      ],
      "metadata": {
        "id": "GfKSt2gH74Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the decision tree\n",
        "> You **cannot** modify the values of these attributes in this part"
      ],
      "metadata": {
        "id": "BZqSVoJ48a3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = x_train.shape[1]"
      ],
      "metadata": {
        "id": "vSlZ7FVB8eau"
      },
      "execution_count": 614,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished the function '*classify_data()*' below, however, you can modify this function if you prefer completing it on your own way."
      ],
      "metadata": {
        "id": "FrK-YqLmLH8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_data(instance, tree):\n",
        "  \"\"\"\n",
        "  This function will predict/classify the input instance\n",
        "  args:\n",
        "  * instance: a instance(case) to be predicted\n",
        "  return:\n",
        "  * answer: the prediction result (the classification result)\n",
        "  \"\"\"\n",
        "  equation = list(tree.keys())[0] \n",
        "  if equation.split()[1] == '<=':\n",
        "    temp_feature = equation.split()[0]\n",
        "    temp_threshold = equation.split()[2]\n",
        "    if instance[temp_feature] > float(temp_threshold):\n",
        "      answer = tree[equation][1]\n",
        "    else:\n",
        "      answer = tree[equation][0]\n",
        "  else:\n",
        "    if instance[equation.split()[0]] in (equation.split()[2]):\n",
        "      answer = tree[equation][0]\n",
        "    else:\n",
        "      answer = tree[equation][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    return classify_data(instance, answer)\n",
        "\n",
        "\n",
        "def make_prediction(tree, data):\n",
        "  \"\"\"\n",
        "  This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
        "  args:\n",
        "  * tree: the decision tree\n",
        "  * data: the data to predict\n",
        "  return:\n",
        "  * y_prediction: the predictions\n",
        "  \"\"\"\n",
        "  \n",
        "  # [Note] You can call the function classify_data() to predict the label of each instance\n",
        "  #y_prediction = data.apply(classify_data, axis = 1, args = (tree,))\n",
        "  y_prediction = []\n",
        "  index = data.index.tolist()\n",
        "  for i in index:\n",
        "      y_prediction.append(classify_data(data.loc[i],tree))      \n",
        "\n",
        "  return y_prediction\n",
        "\n",
        "\n",
        "def calculate_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  This function will calculate the f1-score of the predictions\n",
        "  args:\n",
        "  * y_true: the ground truth\n",
        "  * y_pred: the predictions\n",
        "  return:\n",
        "  * score: the f1-score\n",
        "  \"\"\"\n",
        "  \"\"\"TP, FP, TN, FN = 0, 0, 0, 0\n",
        "  a = len(y_true) + 1\n",
        "  for i in range(a):\n",
        "      if   (y_true[i] == 0) & (y_pred[i] == 0):\n",
        "          TP += 1\n",
        "      elif (y_true[i] == 0) & (y_pred[i] == 1):\n",
        "          FP += 1\n",
        "      elif (y_true[i] == 1) & (y_pred[i] == 1):\n",
        "          TN += 1\n",
        "      else:\n",
        "          FN += 1\n",
        "\n",
        "  accuracy  = (TP + TN) / (TP + FP + TN + FN) \n",
        "  precision = (TP) / (TP + FP) \n",
        "  recall    = (TP) / (TP + FN) \n",
        "  score  = (2 * precision * recall) / (precision + recall)\n",
        "  \"\"\"\n",
        "  tp = 0\n",
        "  for gt, pred in zip(y_true, y_pred):\n",
        "      if gt == 1 and pred == 1:\n",
        "          tp +=1\n",
        "  \n",
        "  tn = 0\n",
        "  for gt, pred in zip(y_true, y_pred):\n",
        "      if gt == 0 and pred == 0:\n",
        "          tn +=1\n",
        "\n",
        "  fp = 0\n",
        "  for gt, pred in zip(y_true, y_pred):\n",
        "      if gt == 0 and pred == 1:\n",
        "          fp +=1\n",
        "\n",
        "  fn = 0\n",
        "  for gt, pred in zip(y_true, y_pred):\n",
        "      if gt == 1 and pred == 0:\n",
        "          fn +=1\n",
        "  \n",
        "  precision = tp/ (tp + fp)\n",
        "  recall = tp/ (tp + fn) \n",
        "\n",
        "  score = 2 * precision * recall/ (precision + recall)\n",
        "  #score = f1_score(y_true, y_pred)\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "0piZ0blpFXVq"
      },
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
        "\n",
        "y_pred = make_prediction(decision_tree, x_validation)\n",
        "print(y_pred)\n",
        "# [Note] You have to save the value of \"ans_f1score\" the your output file\n",
        "ans_f1score = calculate_score(y_validation, y_pred)\n",
        "print(\"ans_f1score = \", ans_f1score)"
      ],
      "metadata": {
        "id": "3IEu3z3s9TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886b669d-2c47-4cc5-d697-5817d4e8f074"
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "ans_f1score =  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step11 : Write the Output File\n",
        "Save all of your answers in a csv file, named as **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "IzzOKOwn-kod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_path = 'hw2_basic.csv'\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" into the output file\n",
        "basic.append(ans_f1score)\n",
        "print(basic)\n",
        "\n",
        "pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "p0zsaWPL2qXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dadf1f9-26e7-47f0-a3dd-fd2fd216930d"
      },
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9871377743721863, 0.08345988684807151, 0.3522950515812332, 235.5, 'glucose_apache', 10, 'glucose_apache', 'heart_rate_apache', '235.5', '143.5', 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Part** (35%)"
      ],
      "metadata": {
        "id": "tV25IjM7_aEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_advanced.csv**"
      ],
      "metadata": {
        "id": "knH1Ih0Pha7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_data = pd.read_csv('hw2_input_advanced.csv')"
      ],
      "metadata": {
        "id": "FthBdLxRhi9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can split *advanced_data* into training set and validaiton set"
      ],
      "metadata": {
        "id": "vqLH49oBndRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = \n",
        "validation_data = "
      ],
      "metadata": {
        "id": "9l0hLPVjncam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Load the test data\n",
        "Load the input file **hw2_input_test.csv** to make predictions with the pre-trained random forest model"
      ],
      "metadata": {
        "id": "tFgbUY_ajVOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('hw2_input_test.csv')\n",
        "x_test"
      ],
      "metadata": {
        "id": "3hW542KWNxVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Build a Random Forest"
      ],
      "metadata": {
        "id": "mH-0DxyR9qWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the random forest\n",
        "> * You **can** modify the values of these attributes in advanced part\n",
        "> * Each tree can have different attribute values\n",
        "> * There must be **at least** 3 decision trees in the random forest model\n",
        "> * Must use function *build_tree()* to build a random forest model\n",
        "> * These are the parameters you can adjust : \n",
        "\n",
        "\n",
        "    ```\n",
        "    max_depth = \n",
        "    depth = 0\n",
        "    min_samples_split = \n",
        "    \n",
        "    # total number of trees in a random forest\n",
        "    n_trees = \n",
        "\n",
        "    # number of features to train a decision tree\n",
        "    n_features = \n",
        "\n",
        "    # the ratio to select the number of instances\n",
        "    sample_size = \n",
        "    n_samples = int(training_data.shape[0] * sample_size)\n",
        "    ```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xbLxFW597FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the attributes\n",
        "\n"
      ],
      "metadata": {
        "id": "LD8ndJ8ymzG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_forest(data, n_trees, n_features, n_samples):\n",
        "  \"\"\"\n",
        "  This function will build a random forest.\n",
        "  args:\n",
        "  * data: all data that can be used to train a random forest\n",
        "  * n_trees: total number of tree\n",
        "  * n_features: number of features\n",
        "  * n_samples: number of instances\n",
        "  return:\n",
        "  * forest: a random forest with 'n_trees' of decision tree\n",
        "  \"\"\"\n",
        "\n",
        "  # must reuse function build_tree()\n",
        "  tree = build_tree(.....)\n",
        "\n",
        "  return forest"
      ],
      "metadata": {
        "id": "hVl66f1aU36-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest = build_forest(training_data, n_trees, n_features, n_samples)"
      ],
      "metadata": {
        "id": "zylo6C51m3OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Make predictions with the random forest\n",
        "> Note: Please print the f1-score of the predictions of each decision tree"
      ],
      "metadata": {
        "id": "dZb6EEYnnO05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction_forest(forest, data):\n",
        "  \"\"\"\n",
        "  This function will use the pre-trained random forest to make the predictions\n",
        "  args:\n",
        "  * forest: the random forest\n",
        "  * data: the data used to predict\n",
        "  return:\n",
        "  * y_prediction: the predicted results\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  return y_prediction"
      ],
      "metadata": {
        "id": "UbHMZnMDnWpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = make_prediction_forest(forest, x_test)"
      ],
      "metadata": {
        "id": "Hcd70ubwgHq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Write the Output File\n",
        "Save your predictions from the **random forest** in a csv file, named as **hw2_advanced.csv**"
      ],
      "metadata": {
        "id": "2ufa5bP9HveO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced = []\n",
        "for i in range(len(y_pred_test)):\n",
        "  advanced.append(y_pred_test[i])"
      ],
      "metadata": {
        "id": "XdAQcE41JJYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_path = 'hw2_advanced.csv'\n",
        "pd.DataFrame(advanced).to_csv(advanced_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "Pq121klSHwWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}